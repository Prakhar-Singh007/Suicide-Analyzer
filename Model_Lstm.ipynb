{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of Colvolutional Neural Networks "
      ],
      "metadata": {
        "id": "CVgjwzJS5Df0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lCM9vYW5k2G",
        "outputId": "c0aa4051-3ce1-4708-e9b2-bfa673c7ec59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, recall_score, accuracy_score, f1_score, precision_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler\n"
      ],
      "metadata": {
        "id": "m0pzNvQq5yKj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from prettytable import PrettyTable"
      ],
      "metadata": {
        "id": "V4WdnGv454Mz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import nltk\n",
        " nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYgdFUmw0aR7",
        "outputId": "b2692d64-1662-4c01-b7f6-38cb3c3c39c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "_7F5V2JV5-2L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try: \n",
        "    os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")\n",
        "    print(\"Directory changed\")\n",
        "except OSError:\n",
        "    print(\"Error: Can't change the Current Working Directory\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk_8zjHA6E10",
        "outputId": "a3425605-ec19-4a18-da10-a11e1446880c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory changed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define constants\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-5\n",
        "SEED = 4222"
      ],
      "metadata": {
        "id": "F_Xl0A4a6VH3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suicide_detection_df = pd.read_csv('/content/drive/MyDrive/dataset/suicide_detection_final_cleaned.csv', header=0)\n",
        "suicide_detection_df.drop(columns=['text'], axis=1, inplace=True)\n",
        "suicide_detection_df = suicide_detection_df.rename(columns={\"clean_msg\": \"text\"})\n",
        "classes = {\"suicide\": 1, \"non-suicide\": 0}\n",
        "suicide_detection_df = suicide_detection_df.replace({\"class\": classes})\n",
        "suicide_detection_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3ZJfjS6L6ebg",
        "outputId": "6fc441d7-9ca5-40ad-d579-454426e80252"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  class                                               text\n",
              "0           3      0  weird not get affected compliment coming someo...\n",
              "1           4      0  finally almost never hear bad year ever swear ...\n",
              "2           8      1                            need help help cry hard\n",
              "3          13      1                       end tonight not anymore quit\n",
              "4          19      1  took rest sleeping pill painkiller not wait en..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3de991d5-2345-4baf-b740-0e668e95f771\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>weird not get affected compliment coming someo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>finally almost never hear bad year ever swear ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>need help help cry hard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>end tonight not anymore quit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>took rest sleeping pill painkiller not wait en...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3de991d5-2345-4baf-b740-0e668e95f771')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3de991d5-2345-4baf-b740-0e668e95f771 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3de991d5-2345-4baf-b740-0e668e95f771');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(suicide_detection_df['text'], \n",
        "                                                                    suicide_detection_df['class'],\n",
        "                                                                    random_state=SEED,\n",
        "                                                                    test_size=0.2,\n",
        "                                                                    stratify=suicide_detection_df['class'])\n",
        "\n",
        "val_text , test_text , val_labels , test_labels = train_test_split(temp_text ,\n",
        "                                                                   temp_labels,\n",
        "                                                                   random_state=SEED,\n",
        "                                                                   test_size=0.5,\n",
        "                                                                   stratify=temp_labels)\n"
      ],
      "metadata": {
        "id": "ebr7HaCY65_x"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(s.split()) for s in train_text])\n",
        "max_length\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eli_qFkATLah",
        "outputId": "a904c826-516b-4197-c6ec-7985b3ca5d29"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alXC9oUxPXdm",
        "outputId": "32007343-6516-4de4-86ce-3a0e013b24d2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23467     creepy account followed posted something someo...\n",
              "129548    realize kill december recent past friend famil...\n",
              "164329    love clipping hair bleached feel need trim sup...\n",
              "118356    not want alive anymore alone bad person care m...\n",
              "70396     deal someone lying caring not care not one car...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "mESHaIoSU-Pd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_encode(text, max_length=62):\n",
        "    encoded_docs = tokenizer.texts_to_sequences(text)\n",
        "    padded_sequence = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "\n",
        "    return padded_sequence\n",
        "\n",
        "# Tokenize and encode sequences in all datasets\n",
        "tokens_train = tokenize_and_encode(train_text)\n",
        "tokens_val = tokenize_and_encode(val_text)\n",
        "tokens_test = tokenize_and_encode(test_text)\n"
      ],
      "metadata": {
        "id": "i7Zlren2VOIW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(torch.from_numpy(tokens_train), torch.from_numpy(train_labels.to_numpy()))\n",
        "val_data = TensorDataset(torch.from_numpy(tokens_val), torch.from_numpy(val_labels.to_numpy()))"
      ],
      "metadata": {
        "id": "65bZcDYKZfGV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sampler = RandomSampler(train_data)\n",
        "val_sampler = SequentialSampler(val_data)"
      ],
      "metadata": {
        "id": "FuiW-yLtZgv6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "9STTQx0EZmLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "76vaRDPyZi_I"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Word Embeddings "
      ],
      "metadata": {
        "id": "am9AmfIlZuvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "data=pd.read_csv('/content/drive/MyDrive/dataset/suicide_detection_final_cleaned.csv',encoding='utf-8')\n",
        "data['tokens'] = data['clean_msg'].apply(lambda x:nltk.word_tokenize(x))\n",
        "model = Word2Vec(data['tokens'], vector_size=300, min_count=1)\n",
        "model.save(\"word2vec.model\")\n",
        "from gensim.models import KeyedVectors\n",
        "model = KeyedVectors.load(\"word2vec.model\", mmap='r')\n",
        "model.wv['pass']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kMZBD4izI9L",
        "outputId": "a2143258-b37d-4d87-d9dc-a5f110773160"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "memmap([-0.0275037 ,  0.03092316,  0.01424963,  0.2104478 ,  0.18439096,\n",
              "        -0.04258012, -0.05548488,  0.10089509,  0.07837665,  0.06487896,\n",
              "        -0.2357744 ,  0.12273563, -0.0978692 ,  0.11383986,  0.1530465 ,\n",
              "         0.032842  ,  0.15843906,  0.14329489, -0.15406004,  0.07535824,\n",
              "        -0.08195169,  0.03957147,  0.02500191,  0.10166683, -0.25771976,\n",
              "        -0.07971987,  0.17958254, -0.23498257, -0.01239769,  0.12835726,\n",
              "         0.02848144,  0.03733095, -0.07698274, -0.08567388,  0.09311298,\n",
              "         0.2328964 ,  0.0121145 , -0.11823147, -0.25353354,  0.24629658,\n",
              "         0.04803937,  0.19718775,  0.14182425, -0.15369254,  0.04873293,\n",
              "        -0.05590167,  0.13540776, -0.06769478,  0.0887337 , -0.186985  ,\n",
              "         0.02893303, -0.41682333, -0.02093649, -0.21311167, -0.01076264,\n",
              "         0.28085938, -0.05169273, -0.06253446, -0.22706705,  0.10982954,\n",
              "         0.05274032, -0.0441177 ,  0.03290827, -0.05997289, -0.06060196,\n",
              "        -0.12796316, -0.23463586,  0.47914138, -0.0935725 , -0.15975006,\n",
              "         0.06021742,  0.14521585,  0.30652443, -0.04173746, -0.11059444,\n",
              "         0.24643661,  0.3089    ,  0.0535784 , -0.02347027,  0.090803  ,\n",
              "        -0.03976392, -0.3759311 ,  0.07061835, -0.13991609,  0.07780711,\n",
              "         0.04640799, -0.00722286, -0.00634544, -0.22334693,  0.30207813,\n",
              "         0.32799602, -0.06597491,  0.3532315 ,  0.45329222,  0.21570475,\n",
              "        -0.03032623,  0.22175287, -0.11956112, -0.07069324, -0.02981606,\n",
              "        -0.27482843,  0.11731758,  0.07746729,  0.04197597,  0.1063322 ,\n",
              "        -0.19113201, -0.19457085,  0.04388439, -0.08559361, -0.15079163,\n",
              "        -0.32827157,  0.1457693 ,  0.06598532,  0.11186456,  0.06105674,\n",
              "         0.0264717 , -0.24834514, -0.26661718,  0.29628226, -0.1533494 ,\n",
              "         0.3819543 ,  0.00717462,  0.14108898, -0.1464132 ,  0.1277751 ,\n",
              "         0.08922662, -0.07375096, -0.47244453, -0.21097457,  0.25275356,\n",
              "        -0.00120292,  0.27787068,  0.01648782, -0.3305202 , -0.18865559,\n",
              "         0.09708761, -0.24586022,  0.09347357, -0.15266168, -0.33655915,\n",
              "         0.04704676, -0.03781102,  0.27678084, -0.00139092,  0.09132794,\n",
              "        -0.01183712,  0.06989533, -0.30182266,  0.3732813 ,  0.11110552,\n",
              "         0.2134282 , -0.0863078 ,  0.329946  , -0.12657294, -0.12701878,\n",
              "        -0.13845302, -0.2802995 ,  0.03000596, -0.00451602, -0.1716198 ,\n",
              "         0.20041771,  0.21234807, -0.03164925,  0.24755871,  0.00834409,\n",
              "        -0.07820591,  0.17140406, -0.10917705, -0.42804533, -0.03002802,\n",
              "        -0.1700953 ,  0.12954012,  0.04981729, -0.00734733,  0.06618559,\n",
              "        -0.12901536,  0.01223488, -0.1792105 ,  0.15156123, -0.10460239,\n",
              "        -0.2314012 , -0.10164168, -0.17296201,  0.03327458,  0.06849919,\n",
              "         0.01275421,  0.11106613,  0.29065567,  0.14939408,  0.2658486 ,\n",
              "        -0.18498456,  0.21487282, -0.01913284, -0.0551064 ,  0.0669727 ,\n",
              "        -0.2051312 , -0.2183678 ,  0.17963372,  0.07168216,  0.04230036,\n",
              "         0.06150926, -0.02768516, -0.16310173,  0.09183031,  0.03582921,\n",
              "        -0.17673074,  0.06102741, -0.06253286, -0.22911   ,  0.07940237,\n",
              "         0.05228159,  0.0467966 , -0.06219759, -0.09533961,  0.01905641,\n",
              "        -0.04023797,  0.05636983, -0.28441635,  0.12838964, -0.20458232,\n",
              "         0.4928462 ,  0.19064477,  0.07986744, -0.24611594, -0.23415336,\n",
              "        -0.2979641 , -0.05032353, -0.19629177, -0.20191753, -0.0993756 ,\n",
              "         0.01643554, -0.24072738, -0.25760168,  0.13071938,  0.10394937,\n",
              "         0.08297182, -0.23336476,  0.3321549 ,  0.05714213,  0.0347457 ,\n",
              "        -0.05201454, -0.10543104, -0.31755212,  0.04672308,  0.30987254,\n",
              "         0.07841445, -0.23528765,  0.0138118 , -0.21263823, -0.07961377,\n",
              "         0.24872404, -0.18017794,  0.09306716, -0.06934717,  0.1302528 ,\n",
              "         0.15826227,  0.14385484,  0.352883  , -0.2922065 ,  0.01853291,\n",
              "        -0.11543304, -0.02974818,  0.27368852, -0.14426094, -0.0889144 ,\n",
              "        -0.01403222,  0.1543435 ,  0.25676778, -0.1604844 , -0.08674014,\n",
              "        -0.61449087,  0.10231618,  0.02619025, -0.32894742,  0.30594337,\n",
              "        -0.01231154,  0.07972126, -0.31242704,  0.16432717, -0.11171038,\n",
              "        -0.05333957, -0.01848267,  0.01265057,  0.16382088, -0.12539417,\n",
              "        -0.26998502,  0.20169899, -0.1528567 , -0.12418201, -0.0072576 ,\n",
              "         0.02236739, -0.10339033, -0.12088856, -0.25730175,  0.19947334,\n",
              "         0.18215856,  0.17397034,  0.11315751,  0.26993933,  0.12181719],\n",
              "       dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_embedding(model_path):\n",
        "    \"\"\"Load pre-trained Word2Vec embeddings from a Gensim model file.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): Path to the Gensim Word2Vec model file.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping each word to its corresponding embedding vector.\n",
        "    \"\"\"\n",
        "    embedding_dict = {}\n",
        "    model = KeyedVectors.load(model_path)\n",
        "\n",
        "    for word in model.wv.key_to_index.keys():\n",
        "        embedding_dict[word] = model.wv[word]\n",
        "    \n",
        "    return embedding_dict"
      ],
      "metadata": {
        "id": "_bopKiEAZyTe"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_embedding_glove(filename):\n",
        "\tfile = open(filename,'r')\n",
        "\tlines = file.readlines()[1:]\n",
        "\tfile.close()\n",
        "\tembedding = dict()\n",
        "\tfor line in lines:\n",
        "\t\tparts = line.split()\n",
        "\t\tembedding[parts[0]] = np.asarray(parts[1:], dtype='float32')\n",
        "\treturn embedding"
      ],
      "metadata": {
        "id": "YY-A8gLD9-pd"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weight_matrix(embedding, vocab, embedding_dim):\n",
        "\tvocab_size = len(vocab) + 1\n",
        "\tweight_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\tfor word, i in vocab.items():\n",
        "\t\tweight_matrix[i] = embedding.get(word)\n",
        "\n",
        "\treturn weight_matrix"
      ],
      "metadata": {
        "id": "iOyZ0GZQaoBj"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "    num_embeddings, embedding_dim = weights_matrix.shape[0], weights_matrix.shape[1]\n",
        "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    emb_layer.load_state_dict({'weight': torch.from_numpy(weights_matrix)})\n",
        "    if non_trainable:\n",
        "        emb_layer.weight.requires_grad = False\n",
        "\n",
        "    return emb_layer, num_embeddings, embedding_dim"
      ],
      "metadata": {
        "id": "dy6OV3XSbBdE"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_vector(text):\n",
        "\n",
        "    vector = np.zeros(300)\n",
        "    count = 0\n",
        "    for token in text:\n",
        "        try:\n",
        "            vector += model.wv[token]\n",
        "            count += 1\n",
        "        except KeyError:\n",
        "            continue\n",
        "    if count != 0:\n",
        "        vector /= count\n",
        "    return vector\n",
        "\n",
        "data['text_vector'] = data['tokens'].apply(get_text_vector)"
      ],
      "metadata": {
        "id": "RshEmM2G1O4S"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "pqXGB5ab4EZ3",
        "outputId": "6e2e7b05-672f-4d4e-edb1-e8396a3fd0f7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                               text        class  \\\n",
              "0           3  Am I weird I don't get affected by compliments...  non-suicide   \n",
              "1           4  Finally 2020 is almost over... So I can never ...  non-suicide   \n",
              "2           8          i need helpjust help me im crying so hard      suicide   \n",
              "3          13   It ends tonight.I can’t do it anymore. \\nI quit.      suicide   \n",
              "4          19  I took the rest of my sleeping pills and my pa...      suicide   \n",
              "\n",
              "                                           clean_msg  \\\n",
              "0  weird not get affected compliment coming someo...   \n",
              "1  finally almost never hear bad year ever swear ...   \n",
              "2                            need help help cry hard   \n",
              "3                       end tonight not anymore quit   \n",
              "4  took rest sleeping pill painkiller not wait en...   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [weird, not, get, affected, compliment, coming...   \n",
              "1  [finally, almost, never, hear, bad, year, ever...   \n",
              "2                      [need, help, help, cry, hard]   \n",
              "3                 [end, tonight, not, anymore, quit]   \n",
              "4  [took, rest, sleeping, pill, painkiller, not, ...   \n",
              "\n",
              "                                         text_vector  \n",
              "0  [0.7055002152919769, -0.04264983518182167, -0....  \n",
              "1  [0.667242802340876, -0.25702551718462596, -0.3...  \n",
              "2  [0.8219113126397133, 0.33248451287126957, -0.0...  \n",
              "3  [1.0425579726696015, 0.05171641409397125, -0.1...  \n",
              "4  [0.7345938748465135, 0.3454161842282002, 0.066...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e372830-a88e-40b1-8fe3-a2ef83e86ff6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>clean_msg</th>\n",
              "      <th>tokens</th>\n",
              "      <th>text_vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Am I weird I don't get affected by compliments...</td>\n",
              "      <td>non-suicide</td>\n",
              "      <td>weird not get affected compliment coming someo...</td>\n",
              "      <td>[weird, not, get, affected, compliment, coming...</td>\n",
              "      <td>[0.7055002152919769, -0.04264983518182167, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
              "      <td>non-suicide</td>\n",
              "      <td>finally almost never hear bad year ever swear ...</td>\n",
              "      <td>[finally, almost, never, hear, bad, year, ever...</td>\n",
              "      <td>[0.667242802340876, -0.25702551718462596, -0.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>i need helpjust help me im crying so hard</td>\n",
              "      <td>suicide</td>\n",
              "      <td>need help help cry hard</td>\n",
              "      <td>[need, help, help, cry, hard]</td>\n",
              "      <td>[0.8219113126397133, 0.33248451287126957, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>It ends tonight.I can’t do it anymore. \\nI quit.</td>\n",
              "      <td>suicide</td>\n",
              "      <td>end tonight not anymore quit</td>\n",
              "      <td>[end, tonight, not, anymore, quit]</td>\n",
              "      <td>[1.0425579726696015, 0.05171641409397125, -0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>I took the rest of my sleeping pills and my pa...</td>\n",
              "      <td>suicide</td>\n",
              "      <td>took rest sleeping pill painkiller not wait en...</td>\n",
              "      <td>[took, rest, sleeping, pill, painkiller, not, ...</td>\n",
              "      <td>[0.7345938748465135, 0.3454161842282002, 0.066...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e372830-a88e-40b1-8fe3-a2ef83e86ff6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e372830-a88e-40b1-8fe3-a2ef83e86ff6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e372830-a88e-40b1-8fe3-a2ef83e86ff6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_embedding_word2vec = load_embedding('/content/drive/MyDrive/Colab Notebooks/word2vec.model')\n",
        "# get vectors in the right order\n",
        "embedding_vectors_word2vec = get_weight_matrix(raw_embedding_word2vec, tokenizer.word_index, 300)\n",
        "embedding_vectors_word2vec = np.float32(embedding_vectors_word2vec)"
      ],
      "metadata": {
        "id": "Jz8hFGPN7IvJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_embedding_glove = load_embedding_glove('/content/drive/MyDrive/glove/glove.twitter.27B.200d.txt')\n",
        "embedding_vectors_glove = get_weight_matrix(raw_embedding_glove, tokenizer.word_index, 200)\n",
        "embedding_vectors_glove = np.float32(embedding_vectors_glove)"
      ],
      "metadata": {
        "id": "NlNUvoSUCu9A"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for arr in embedding_vectors_glove:\n",
        "    for idx, i in enumerate(arr):\n",
        "        if np.isnan(arr[idx]):\n",
        "            arr[idx] = 0"
      ],
      "metadata": {
        "id": "bJ_ApxBuC0DS"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lstm Architecture"
      ],
      "metadata": {
        "id": "QSr8ApVJdh5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, \n",
        "                 embedding_dim, hidden_dim, n_layers, \n",
        "                 dropout_rate, pre_trained=False, embedding_vectors=None):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        if pre_trained:\n",
        "            self.embedding, num_embeddings, embedding_dim = create_emb_layer(embedding_vectors, True)\n",
        "        else:\n",
        "            # Create word embeddings from the input words\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=dropout_rate, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3) # dropout_rate\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "\n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        \n",
        "        return hidden\n",
        "        "
      ],
      "metadata": {
        "id": "RoW5EMt8dmvG"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "Ozl2c2uhdqb0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "embedding_dim = 300\n",
        "hidden_dim = 128\n",
        "output_size = 1\n",
        "n_layers = 2\n",
        "dropout = 0.5"
      ],
      "metadata": {
        "id": "tCEP-NkUdtYE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# push to GPU\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "seWNH9iqdu1s"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1:No pre trained embedding weights "
      ],
      "metadata": {
        "id": "sx_ZQSiQ-VmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout)\n",
        "\n",
        "print(\"No pre trained embedding weights\")\n",
        "print(model1)\n",
        "print(f'Model 1 has {count_parameters(model1):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEeLKXPl-Ukn",
        "outputId": "f79dd20b-ae7a-40ef-b389-2eaeeda232cb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No pre trained embedding weights\n",
            "SentimentLSTM(\n",
            "  (embedding): Embedding(32372, 300)\n",
            "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n",
            "Model 1 has 10,063,985 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2:word2vec custom trained embedding weights"
      ],
      "metadata": {
        "id": "MboHufm_-k3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout, \n",
        "                       pre_trained=True, embedding_vectors=embedding_vectors_word2vec)\n",
        "model2.embedding.weight.data.copy_(torch.from_numpy(embedding_vectors_word2vec))\n",
        "\n",
        "print(\"With Word2Vec pre trained embedding weights\")\n",
        "print(model2)\n",
        "print(f'Model 2 has {count_parameters(model2):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPW0X8Ds-sFP",
        "outputId": "dccae4e9-a0e3-40de-999f-f420b9424e55"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With Word2Vec pre trained embedding weights\n",
            "SentimentLSTM(\n",
            "  (embedding): Embedding(32372, 300)\n",
            "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n",
            "Model 2 has 352,385 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### glove Twitter dataset (200d) pre trained embedding weights "
      ],
      "metadata": {
        "id": "2KLaap_o-uHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = SentimentLSTM(vocab_size, output_size, 200, hidden_dim, n_layers, dropout, \n",
        "                       pre_trained=True, embedding_vectors=embedding_vectors_glove)\n",
        "model3.embedding.weight.data.copy_(torch.from_numpy(embedding_vectors_glove))\n",
        "\n",
        "print(\"With gloVe pre trained embedding weights\")\n",
        "print(model3)\n",
        "print(f'Model 3 has {count_parameters(model3):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99hX-WKf-3nO",
        "outputId": "a524a6d7-5ef6-4446-e95f-a0d4fe0d687a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With gloVe pre trained embedding weights\n",
            "SentimentLSTM(\n",
            "  (embedding): Embedding(32372, 200)\n",
            "  (lstm): LSTM(200, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n",
            "Model 3 has 301,185 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# functions to Train and Evaluate the model "
      ],
      "metadata": {
        "id": "QBZrywYH-6NT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum()/len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "I6yHYdJJ-_FH"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches of train data\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('Batch {:>5,} of {:>5,}.'.format(step, len(train_dataloader)))\n",
        "        \n",
        "        # push the batch to gpu\n",
        "        # batch = [r.to(device) for r in batch]\n",
        "\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "        # initialize hidden state\n",
        "        h = model.init_hidden(len(inputs))\n",
        "\n",
        "        # move to gpu\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Create new variables for the hidden state\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # get model predictions for current batch\n",
        "        preds, h = model(inputs, h)\n",
        "        \n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = criterion(preds.squeeze(), labels.float())\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "\n",
        "        # compute accuracy\n",
        "        acc = binary_accuracy(preds, labels)\n",
        "\n",
        "        # add on to the total accuracy\n",
        "        total_accuracy += acc.item()\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        # append the model predictions\n",
        "        total_preds.append(preds)\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # compute the training acc of the epoch\n",
        "    avg_acc = total_accuracy / len(train_dataloader)\n",
        "\n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    # returns the loss, accuracy and predictions\n",
        "    return avg_loss, avg_acc, total_preds"
      ],
      "metadata": {
        "id": "2v5_9iDm_EkF"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "    print(\"\\nEvaluating...\")\n",
        "\n",
        "    # deactivate dropout layers\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches\n",
        "    for step, batch in enumerate(val_dataloader):\n",
        "\n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('Batch {:>5,} of {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        # batch = [t.to(device) for t in batch]\n",
        "\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "        # initialize hidden state\n",
        "        val_h = model.init_hidden(len(inputs))\n",
        "\n",
        "        # move to gpu\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Create new variables for the hidden state\n",
        "        val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # model predictions\n",
        "            preds, val_h = model(inputs, val_h)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = criterion(preds.squeeze(), labels.float())\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            acc = binary_accuracy(preds, labels)\n",
        "\n",
        "            total_accuracy += acc.item()\n",
        "            \n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            \n",
        "            total_preds.append(preds)\n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "\n",
        "    # compute the validation acc of the epoch\n",
        "    avg_acc = total_accuracy / len(val_dataloader)\n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, avg_acc, total_preds"
      ],
      "metadata": {
        "id": "-rsoy1QJ_I4W"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: No pre trained embedding weights"
      ],
      "metadata": {
        "id": "JTzG49xTAJU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the optimizer\n",
        "optimizer = optim.Adam(model1.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# push to GPU\n",
        "model = model1.to(device)\n",
        "\n",
        "MODEL_WEIGHTS_PATH = 'model'"
      ],
      "metadata": {
        "id": "2dvFdyokAKX_"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "model1_train_losses = []\n",
        "model1_valid_losses = []\n",
        "\n",
        "# empty lists to store training and validation acc of each epoch\n",
        "model1_train_accuracies = []\n",
        "model1_valid_accuracies = []\n",
        "\n",
        "# for each epoch\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch+1, EPOCHS))\n",
        "    \n",
        "    # train model\n",
        "    train_loss, train_acc, _ = train()\n",
        "\n",
        "    # evaluate model\n",
        "    valid_loss, valid_acc, _ = evaluate()\n",
        "\n",
        "    # save best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_WEIGHTS_PATH)\n",
        "    \n",
        "    # append training and validation loss\n",
        "    model1_train_losses.append(train_loss)\n",
        "    model1_valid_losses.append(valid_loss)\n",
        "\n",
        "    # append training and validation acc\n",
        "    model1_train_accuracies.append(train_acc)\n",
        "    model1_valid_accuracies.append(valid_acc)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "    print(f'\\nTraining Accuracy: {train_acc:.3f}')\n",
        "    print(f'Validation Accuracy: {valid_acc:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzbKOjWoAPKq",
        "outputId": "98d1ed08-fc5e-4d76-f36a-2b4472dbf483"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.658\n",
            "Validation Loss: 0.651\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n",
            "\n",
            " Epoch 2 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.642\n",
            "Validation Loss: 0.635\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n",
            "\n",
            " Epoch 3 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.626\n",
            "Validation Loss: 0.619\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n",
            "\n",
            " Epoch 4 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.615\n",
            "Validation Loss: 0.613\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n",
            "\n",
            " Epoch 5 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.612\n",
            "Validation Loss: 0.612\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load weights of best model cnn\n",
        "model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQiP0YV5ARsp",
        "outputId": "fe922cca-0f8d-4c6d-bd0c-4315c679f1ea"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run trained model 1 on Test dataset"
      ],
      "metadata": {
        "id": "HQnb3AERATmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create Tensor datasets\n",
        "test_data = TensorDataset(torch.from_numpy(tokens_test), torch.from_numpy(test_labels.to_numpy()))\n",
        "\n",
        "# Sampler for sampling the data\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "\n",
        "# DataLoader\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "to3lTJxiAUoV"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# empty list to save the model predictions\n",
        "total_preds = []\n",
        "\n",
        "# iterate over batches\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "        print('Batch {:>5,} of {:>5,}.'.format(step, len(test_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    # batch = [t.to(device) for t in batch]\n",
        "\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "    # initialize hidden state\n",
        "    test_h = model.init_hidden(len(inputs)) # BATCH_SIZE # to discuss!!!!!!!!!\n",
        "\n",
        "    # move to gpu\n",
        "    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # Create new variables for the hidden state\n",
        "    test_h = tuple([each.data for each in test_h])\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # model predictions\n",
        "        preds, test_h = model(inputs, test_h)\n",
        "\n",
        "        # convert output probabilities to predicted class (0 or 1)\n",
        "        preds = torch.round(preds.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        total_preds.append(preds)\n",
        "\n",
        "# reshape the predictions in form of (number of samples, no. of classes)\n",
        "total_preds = np.concatenate(total_preds, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4eAB0NkAYQi",
        "outputId": "46b77146-39cb-4813-b5fc-1a744c286936"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 Summary"
      ],
      "metadata": {
        "id": "qgqXU252Aa_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_labels, total_preds, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkZgvCu8AdPK",
        "outputId": "2dafc334-2157-480f-a332-f1969081b3cf"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8808    0.9340    0.9066     10520\n",
            "           1     0.8705    0.7781    0.8217      5994\n",
            "\n",
            "    accuracy                         0.8774     16514\n",
            "   macro avg     0.8756    0.8561    0.8642     16514\n",
            "weighted avg     0.8770    0.8774    0.8758     16514\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_test_accuracy_score = accuracy_score(test_labels, total_preds)\n",
        "model_1_test_precision_score = precision_score(test_labels, total_preds)\n",
        "model_1_test_recall_score = recall_score(test_labels, total_preds)\n",
        "model_1_test_f1_score = f1_score(test_labels, total_preds)"
      ],
      "metadata": {
        "id": "M_h0U77FAfXL"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: Word2Vec pre trained embedding weights"
      ],
      "metadata": {
        "id": "zRMMKX5bAjje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the optimizer\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# push to GPU\n",
        "model = model2.to(device)\n",
        "\n",
        "MODEL_WEIGHTS_PATH = 'model2'"
      ],
      "metadata": {
        "id": "s8Pj2b34Am7D"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Train and Evaluate Model 2"
      ],
      "metadata": {
        "id": "VCoO0V96Arqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "model2_train_losses = []\n",
        "model2_valid_losses = []\n",
        "\n",
        "# empty lists to store training and validation acc of each epoch\n",
        "model2_train_accuracies = []\n",
        "model2_valid_accuracies = []\n",
        "\n",
        "# for each epoch\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch+1, EPOCHS))\n",
        "    \n",
        "    # train model\n",
        "    train_loss, train_acc, _ = train()\n",
        "\n",
        "    # evaluate model\n",
        "    valid_loss, valid_acc, _ = evaluate()\n",
        "\n",
        "    # save best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_WEIGHTS_PATH)\n",
        "    \n",
        "    # append training and validation loss\n",
        "    model2_train_losses.append(train_loss)\n",
        "    model2_valid_losses.append(valid_loss)\n",
        "\n",
        "    # append training and validation acc\n",
        "    model2_train_accuracies.append(train_acc)\n",
        "    model2_valid_accuracies.append(valid_acc)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "    print(f'\\nTraining Accuracy: {train_acc:.3f}')\n",
        "    print(f'Validation Accuracy: {valid_acc:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIrmlRsXAnfj",
        "outputId": "8f2a15fc-d8cb-46f0-f40b-1dbe23240c21"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.666\n",
            "Validation Loss: 0.616\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n",
            "\n",
            " Epoch 2 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.607\n",
            "Validation Loss: 0.604\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n",
            "\n",
            " Epoch 3 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.600\n",
            "Validation Loss: 0.599\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n",
            "\n",
            " Epoch 4 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.598\n",
            "Validation Loss: 0.598\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n",
            "\n",
            " Epoch 5 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.596\n",
            "Validation Loss: 0.597\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load weights of best model lstm\n",
        "model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3umyICYAxKF",
        "outputId": "ff546753-0abf-4b25-a811-6b70985e5f05"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run trained model 2 on Test dataset"
      ],
      "metadata": {
        "id": "AvcUCzwSAyEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create Tensor datasets\n",
        "test_data = TensorDataset(torch.from_numpy(tokens_test), torch.from_numpy(test_labels.to_numpy()))\n",
        "\n",
        "# Sampler for sampling the data\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "\n",
        "# DataLoader\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "EJArHsRaA09h"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# empty list to save the model predictions\n",
        "total_preds = []\n",
        "\n",
        "# iterate over batches\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "        print('Batch {:>5,} of {:>5,}.'.format(step, len(test_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    # batch = [t.to(device) for t in batch]\n",
        "\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "    # initialize hidden state\n",
        "    test_h = model.init_hidden(len(inputs)) # BATCH_SIZE # to discuss!!!!!!!!!\n",
        "\n",
        "    # move to gpu\n",
        "    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # Create new variables for the hidden state\n",
        "    test_h = tuple([each.data for each in test_h])\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # model predictions\n",
        "        preds, test_h = model(inputs, test_h)\n",
        "\n",
        "        # convert output probabilities to predicted class (0 or 1)\n",
        "        preds = torch.round(preds.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        total_preds.append(preds)\n",
        "\n",
        "# reshape the predictions in form of (number of samples, no. of classes)\n",
        "total_preds = np.concatenate(total_preds, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVUno3_WA29_",
        "outputId": "e00f5022-60d0-4839-84b4-ee8829ebfa7f"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2 Summary"
      ],
      "metadata": {
        "id": "d6lFyRgZA59X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_labels, total_preds, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kjuShQrA8Qw",
        "outputId": "d4da8808-f848-4da6-f353-d65d5faeb758"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9180    0.9498    0.9337     10520\n",
            "           1     0.9062    0.8512    0.8778      5994\n",
            "\n",
            "    accuracy                         0.9140     16514\n",
            "   macro avg     0.9121    0.9005    0.9057     16514\n",
            "weighted avg     0.9138    0.9140    0.9134     16514\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_test_accuracy_score = accuracy_score(test_labels, total_preds)\n",
        "model_2_test_precision_score = precision_score(test_labels, total_preds)\n",
        "model_2_test_recall_score = recall_score(test_labels, total_preds)\n",
        "model_2_test_f1_score = f1_score(test_labels, total_preds)"
      ],
      "metadata": {
        "id": "aPpZwlQaA-rB"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: gloVe Twitter dataset (200d) pre trained embedding weights"
      ],
      "metadata": {
        "id": "kp3WQ2Z2BBc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the optimizer\n",
        "optimizer = optim.Adam(model3.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# push to GPU\n",
        "model = model3.to(device)\n",
        "\n",
        "MODEL_WEIGHTS_PATH = 'model3'"
      ],
      "metadata": {
        "id": "xU_CuXIoBae0"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and Evaluate Model 3"
      ],
      "metadata": {
        "id": "BV_f6FcYBgdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "model3_train_losses = []\n",
        "model3_valid_losses = []\n",
        "\n",
        "# empty lists to store training and validation acc of each epoch\n",
        "model3_train_accuracies = []\n",
        "model3_valid_accuracies = []\n",
        "\n",
        "# for each epoch\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch+1, EPOCHS))\n",
        "    \n",
        "    # train model\n",
        "    train_loss, train_acc, _ = train()\n",
        "\n",
        "    # evaluate model\n",
        "    valid_loss, valid_acc, _ = evaluate()\n",
        "\n",
        "    # save best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_WEIGHTS_PATH)\n",
        "    \n",
        "    # append training and validation loss\n",
        "    model3_train_losses.append(train_loss)\n",
        "    model3_valid_losses.append(valid_loss)\n",
        "\n",
        "    # append training and validation acc\n",
        "    model3_train_accuracies.append(train_acc)\n",
        "    model3_valid_accuracies.append(valid_acc)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "    print(f'\\nTraining Accuracy: {train_acc:.3f}')\n",
        "    print(f'Validation Accuracy: {valid_acc:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esr9TG16Bink",
        "outputId": "f66897d0-5c44-42b3-afbd-7f0a0957ce0a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.681\n",
            "Validation Loss: 0.633\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n",
            "\n",
            " Epoch 2 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.626\n",
            "Validation Loss: 0.618\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n",
            "\n",
            " Epoch 3 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.616\n",
            "Validation Loss: 0.615\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n",
            "\n",
            " Epoch 4 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.612\n",
            "Validation Loss: 0.611\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n",
            "\n",
            " Epoch 5 / 5\n",
            "Batch    50 of 4,129.\n",
            "Batch   100 of 4,129.\n",
            "Batch   150 of 4,129.\n",
            "Batch   200 of 4,129.\n",
            "Batch   250 of 4,129.\n",
            "Batch   300 of 4,129.\n",
            "Batch   350 of 4,129.\n",
            "Batch   400 of 4,129.\n",
            "Batch   450 of 4,129.\n",
            "Batch   500 of 4,129.\n",
            "Batch   550 of 4,129.\n",
            "Batch   600 of 4,129.\n",
            "Batch   650 of 4,129.\n",
            "Batch   700 of 4,129.\n",
            "Batch   750 of 4,129.\n",
            "Batch   800 of 4,129.\n",
            "Batch   850 of 4,129.\n",
            "Batch   900 of 4,129.\n",
            "Batch   950 of 4,129.\n",
            "Batch 1,000 of 4,129.\n",
            "Batch 1,050 of 4,129.\n",
            "Batch 1,100 of 4,129.\n",
            "Batch 1,150 of 4,129.\n",
            "Batch 1,200 of 4,129.\n",
            "Batch 1,250 of 4,129.\n",
            "Batch 1,300 of 4,129.\n",
            "Batch 1,350 of 4,129.\n",
            "Batch 1,400 of 4,129.\n",
            "Batch 1,450 of 4,129.\n",
            "Batch 1,500 of 4,129.\n",
            "Batch 1,550 of 4,129.\n",
            "Batch 1,600 of 4,129.\n",
            "Batch 1,650 of 4,129.\n",
            "Batch 1,700 of 4,129.\n",
            "Batch 1,750 of 4,129.\n",
            "Batch 1,800 of 4,129.\n",
            "Batch 1,850 of 4,129.\n",
            "Batch 1,900 of 4,129.\n",
            "Batch 1,950 of 4,129.\n",
            "Batch 2,000 of 4,129.\n",
            "Batch 2,050 of 4,129.\n",
            "Batch 2,100 of 4,129.\n",
            "Batch 2,150 of 4,129.\n",
            "Batch 2,200 of 4,129.\n",
            "Batch 2,250 of 4,129.\n",
            "Batch 2,300 of 4,129.\n",
            "Batch 2,350 of 4,129.\n",
            "Batch 2,400 of 4,129.\n",
            "Batch 2,450 of 4,129.\n",
            "Batch 2,500 of 4,129.\n",
            "Batch 2,550 of 4,129.\n",
            "Batch 2,600 of 4,129.\n",
            "Batch 2,650 of 4,129.\n",
            "Batch 2,700 of 4,129.\n",
            "Batch 2,750 of 4,129.\n",
            "Batch 2,800 of 4,129.\n",
            "Batch 2,850 of 4,129.\n",
            "Batch 2,900 of 4,129.\n",
            "Batch 2,950 of 4,129.\n",
            "Batch 3,000 of 4,129.\n",
            "Batch 3,050 of 4,129.\n",
            "Batch 3,100 of 4,129.\n",
            "Batch 3,150 of 4,129.\n",
            "Batch 3,200 of 4,129.\n",
            "Batch 3,250 of 4,129.\n",
            "Batch 3,300 of 4,129.\n",
            "Batch 3,350 of 4,129.\n",
            "Batch 3,400 of 4,129.\n",
            "Batch 3,450 of 4,129.\n",
            "Batch 3,500 of 4,129.\n",
            "Batch 3,550 of 4,129.\n",
            "Batch 3,600 of 4,129.\n",
            "Batch 3,650 of 4,129.\n",
            "Batch 3,700 of 4,129.\n",
            "Batch 3,750 of 4,129.\n",
            "Batch 3,800 of 4,129.\n",
            "Batch 3,850 of 4,129.\n",
            "Batch 3,900 of 4,129.\n",
            "Batch 3,950 of 4,129.\n",
            "Batch 4,000 of 4,129.\n",
            "Batch 4,050 of 4,129.\n",
            "Batch 4,100 of 4,129.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n",
            "\n",
            "Training Loss: 0.610\n",
            "Validation Loss: 0.612\n",
            "\n",
            "Training Accuracy: 0.363\n",
            "Validation Accuracy: 0.363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load weights of best model lstm\n",
        "model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGnNo0QxIxIz",
        "outputId": "661fc656-c8a1-4e2f-fe41-79cc63ef97b9"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run trained model 3 on Test dataset"
      ],
      "metadata": {
        "id": "Hv1mR1JyCFdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create Tensor datasets\n",
        "test_data = TensorDataset(torch.from_numpy(tokens_test), torch.from_numpy(test_labels.to_numpy()))\n",
        "\n",
        "# Sampler for sampling the data\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "\n",
        "# DataLoader\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "7UFx2OwOCG8Q"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# empty list to save the model predictions\n",
        "total_preds = []\n",
        "\n",
        "# iterate over batches\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "        print('Batch {:>5,} of {:>5,}.'.format(step, len(test_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    # batch = [t.to(device) for t in batch]\n",
        "\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "    # initialize hidden state\n",
        "    test_h = model.init_hidden(len(inputs)) # BATCH_SIZE # to discuss!!!!!!!!!\n",
        "\n",
        "    # move to gpu\n",
        "    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # Create new variables for the hidden state\n",
        "    test_h = tuple([each.data for each in test_h])\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # model predictions\n",
        "        preds, test_h = model(inputs, test_h)\n",
        "\n",
        "        # convert output probabilities to predicted class (0 or 1)\n",
        "        preds = torch.round(preds.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        total_preds.append(preds)\n",
        "\n",
        "# reshape the predictions in form of (number of samples, no. of classes)\n",
        "total_preds = np.concatenate(total_preds, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvTeWIUWCITy",
        "outputId": "96684597-dc4e-4d77-dfb0-871adae94e01"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch    50 of   517.\n",
            "Batch   100 of   517.\n",
            "Batch   150 of   517.\n",
            "Batch   200 of   517.\n",
            "Batch   250 of   517.\n",
            "Batch   300 of   517.\n",
            "Batch   350 of   517.\n",
            "Batch   400 of   517.\n",
            "Batch   450 of   517.\n",
            "Batch   500 of   517.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3 Summary"
      ],
      "metadata": {
        "id": "D1WkQfcHCMJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_labels, total_preds, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDEPh5d_CMpD",
        "outputId": "0feddec7-edb4-4b79-a1ad-5a9cb8f1498e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8773    0.9425    0.9087     10520\n",
            "           1     0.8839    0.7686    0.8222      5994\n",
            "\n",
            "    accuracy                         0.8794     16514\n",
            "   macro avg     0.8806    0.8555    0.8655     16514\n",
            "weighted avg     0.8797    0.8794    0.8773     16514\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_test_accuracy_score = accuracy_score(test_labels, total_preds)\n",
        "model_3_test_precision_score = precision_score(test_labels, total_preds)\n",
        "model_3_test_recall_score = recall_score(test_labels, total_preds)\n",
        "model_3_test_f1_score = f1_score(test_labels, total_preds)"
      ],
      "metadata": {
        "id": "dVi_Af4XCNs7"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison across 3 models"
      ],
      "metadata": {
        "id": "LMTOCU29CR8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table = PrettyTable()\n",
        "table.field_names = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "\n",
        "table.add_row(['LSTM without pre trained embedding weights', \n",
        "               format(model_1_test_accuracy_score, '.4f'), \n",
        "               format(model_1_test_precision_score, '.4f'), \n",
        "               format(model_1_test_recall_score, '.4f'), \n",
        "               format(model_1_test_f1_score, '.4f')])\n",
        "\n",
        "table.add_row(['LSTM with Word2Vec pre trained embedding weights', \n",
        "               format(model_2_test_accuracy_score, '.4f'), \n",
        "               format(model_2_test_precision_score, '.4f'), \n",
        "               format(model_2_test_recall_score, '.4f'), \n",
        "               format(model_2_test_f1_score, '.4f')])\n",
        "\n",
        "table.add_row(['LSTM with gloVe Twitter (200d) pre trained embedding weights', \n",
        "               format(model_3_test_accuracy_score, '.4f'), \n",
        "               format(model_3_test_precision_score, '.4f'), \n",
        "               format(model_3_test_recall_score, '.4f'), \n",
        "               format(model_3_test_f1_score, '.4f')])\n",
        "print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uohuSKzZCSV4",
        "outputId": "0dc8aba4-7259-4a7f-deda-d0834c34e1a9"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------+----------+-----------+--------+----------+\n",
            "|                            Model                             | Accuracy | Precision | Recall | F1 Score |\n",
            "+--------------------------------------------------------------+----------+-----------+--------+----------+\n",
            "|          LSTM without pre trained embedding weights          |  0.8774  |   0.8705  | 0.7781 |  0.8217  |\n",
            "|       LSTM with Word2Vec pre trained embedding weights       |  0.9140  |   0.9062  | 0.8512 |  0.8778  |\n",
            "| LSTM with gloVe Twitter (200d) pre trained embedding weights |  0.8794  |   0.8839  | 0.7686 |  0.8222  |\n",
            "+--------------------------------------------------------------+----------+-----------+--------+----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(model1_train_accuracies, \"r-\")\n",
        "plt.plot(model1_valid_accuracies, \"r--\")\n",
        "plt.plot(model2_train_accuracies, \"b-\")\n",
        "plt.plot(model2_valid_accuracies, \"b--\")\n",
        "plt.plot(model3_train_accuracies, \"g-\")\n",
        "plt.plot(model3_valid_accuracies, \"g--\")\n",
        "plt.title('Comparison of accuracies across CNN models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train (model 1)', 'validation (model 1)', 'train (model 2)', 'validation (model 2)', 'train (model 3)', 'validation (model 3)'], \n",
        "           bbox_to_anchor=(1, 1))\n",
        "           #loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "2qDSTS39CZQW",
        "outputId": "af2fa7a7-de00-4228-c730-797de15b2c5a"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_name = 'Model1.pt'\n",
        "path = F\"/content/drive/MyDrive/Colab Notebooks/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "YZWFcBLwKbmp"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('/content/drive/MyDrive/Colab Notebooks/Model1.pt')"
      ],
      "metadata": {
        "id": "ynSuooKCMFSX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create Tensor datasets\n",
        "text = [\"i just wanna die \"]\n",
        "txt=tokenize_and_encode(text)\n",
        "txt"
      ],
      "metadata": {
        "id": "6vIzReR8MfFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1281c8f-632b-4309-bb5d-ba302ff0c0d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20695,    32,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_preds)"
      ],
      "metadata": {
        "id": "16frwLfKNLyF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}